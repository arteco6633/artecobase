# План реализации парсинга и синхронизации наличия материалов

## Цель
Парсинг данных о наличии материалов с сайта dreviz-shop.ru по артикулу и тиснению, синхронизация с проектом и автоматическое ежедневное обновление.

## Анализ задачи

С сайта https://dreviz-shop.ru нужно получать:
- Артикул товара
- Тиснение (например, PR, PE, MP, SM, TS, LF и т.д.)
- Наличие (количество в наличии)
- Цену
- Размеры (например, 2750*1830*16)

## Архитектура решения

### Вариант 1: Supabase Edge Functions (Рекомендуется)
- Edge Function для парсинга
- Supabase Cron Jobs для автоматического запуска
- Хранение данных в таблице `materials` или расширение таблицы `documents`

### Вариант 2: Vercel Serverless Functions
- API Route в Next.js/Vercel
- Vercel Cron Jobs
- Интеграция с Supabase

### Вариант 3: Отдельный сервис
- Node.js сервис для парсинга
- Планировщик задач (cron)
- API для синхронизации

## Этапы реализации

### Этап 1: Подготовка структуры данных
1. Создать таблицу `materials` в Supabase или расширить существующую структуру
2. Поля: артикул, тиснение, толщина, наличие, цена, последнее обновление
3. Связь с существующими таблицами документов

### Этап 2: Парсинг данных
1. Изучить структуру HTML/API сайта dreviz-shop.ru
2. Создать функцию парсинга (через API, если доступно, или HTML парсинг)
3. Обработка данных и извлечение нужных полей

### Этап 3: Синхронизация
1. Функция сравнения и обновления данных
2. Логирование изменений
3. Обработка ошибок

### Этап 4: Автоматизация
1. Настройка ежедневного запуска
2. Мониторинг и уведомления об ошибках

## Вопросы для уточнения

1. Как идентифицировать материалы в нашей системе? (артикул + тиснение?)
2. Нужно ли хранить историю изменений наличия?
3. Как обрабатывать материалы, которых нет на сайте?
4. Нужны ли уведомления об изменениях наличия?

## Технические детали

### Парсинг сайта
- Сайт может использовать JavaScript для рендеринга (нужен headless browser)
- Или может быть доступен API
- Необходимо обработать пагинацию (713 товаров на 36 страниц)

### Рекомендуемые библиотеки
- Для парсинга: `cheerio` (HTML) или `puppeteer`/`playwright` (JS рендеринг)
- Для HTTP запросов: `axios` или `fetch`
- Для планировщика: Supabase Cron или Vercel Cron
